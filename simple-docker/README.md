Docker-Hadoop
=============

#### 安装Docker Centos6

```
yum install epel-release
yum install docker-io

service docker start
```

#### 生成Docker-Hadoop

```
git clone https://github.com/winse/docker-hadoop.git
cd docker-hadoop
# 在Dockerfile中使用了本地jdk和hadoop文件！
docker build -t spark-yarn .
```

运行之前，需要调整Dockerfile依赖文件地址。先把压缩包下载到本地后，然后启用tomcat（不太推荐直接放build目录，这样直接build整个镜像会很大！）。

```
[root@docker docker-hadoop]# ll -h
total 462M
-rw-r--r--. 1 root root 2.0K Oct  2 10:20 Dockerfile
drwxr-xr-x. 3 root root 4.0K Oct  2 05:39 etc
-rw-r--r--. 1 root root 142M Sep  6 07:43 hadoop-2.5.1.tar.gz
-rw-r--r--. 1 root root 136M Oct  1 22:11 jdk-7u67-linux-x64.tar.gz
-rw-r--r--. 1 root root  12K Oct  2 08:42 LICENSE
-rw-r--r--. 1 root root 1.3K Oct  2 11:29 README.md
-rw-r--r--. 1 root root 185M Oct 16 00:09 spark-1.1.0-bin-2.5.1.tgz
drwxr-xr-x. 2 root root 4.0K Oct  2 00:56 WEB-INF

[root@docker docker-hadoop]# cat ~/apache-tomcat-7.0.37/conf/Catalina/localhost/hadoop.xml 
<?xml version='1.0' encoding='utf-8'?>

<Context path="/hadoop" docBase="/root/docker-hadoop">
</Context>

# 格式化xml
[root@docker docker-hadoop]# xmllint --format WEB-INF/web.xml 

```

注： `172.17.42.1` 为docker安装后创建的网卡的地址。

#### 运行测试命令

**安装DNS服务器**

用于docker容器之间通过域名来访问。也可以跳过这个步骤，启动容器后直接修改相应的 `/etc/hosts` ；或者创建一个network，通过docker容器的名称来互相访问，等等。

```
[root@docker ~]# yum install dnsmasq -y

[root@docker ~]# cp /etc/resolv.conf /etc/resolv.dnsmasq.conf 
[root@docker ~]# touch /etc/dnsmasq.hosts

[root@docker ~]# vi /etc/resolv.conf
[root@docker ~]# cat /etc/resolv.conf
; generated by /sbin/dhclient-script
nameserver 127.0.0.1 

[root@docker ~]# vi /etc/dnsmasq.conf
[root@docker ~]# cat /etc/dnsmasq.conf
...
resolv-file=/etc/resolv.dnsmasq.conf
...
addn-hosts=/etc/dnsmasq.hosts

[root@docker ~]# service dnsmasq restart
```

启动集群：

```
[root@docker ~]# docker run -d  --dns 172.17.42.1 --name slaver1 -h slaver1 spark-yarn
[root@docker ~]# docker run -d  --dns 172.17.42.1 --name slaver2 -h slaver2 spark-yarn
[root@docker ~]# docker run -d  --dns 172.17.42.1 --name master -h master spark-yarn

[root@docker ~]# docker ps 
CONTAINER ID        IMAGE               COMMAND                CREATED             STATUS              PORTS               NAMES
f6e63b311e60        hadoop:latest       /bin/sh -c '/usr/sbi   6 seconds ago       Up 5 seconds        22/tcp              master              
454ae2c3e435        hadoop:latest       /bin/sh -c '/usr/sbi   13 seconds ago      Up 12 seconds       22/tcp              slaver2             
7698230a03fb        hadoop:latest       /bin/sh -c '/usr/sbi   21 seconds ago      Up 20 seconds       22/tcp              slaver1             

[root@docker ~]# docker ps | grep spark-yarn | awk '{print $1}' | xargs -I{} docker inspect -f '{{.NetworkSettings.IPAddress}} {{.Config.Hostname}}' {} > /etc/dnsmasq.hosts 
[root@docker ~]# service dnsmasq restart

[root@docker ~]# ssh-copy-id hadoop@master

# 进入master节点，启动集群
[root@docker ~]# ssh hadoop@master

  [hadoop@master ~]$ cd /opt/hadoop-2.5.1/

  [hadoop@master hadoop-2.5.1]$ ssh-copy-id master
  [hadoop@master hadoop-2.5.1]$ ssh-copy-id localhost
  [hadoop@master hadoop-2.5.1]$ ssh-copy-id slaver1
  [hadoop@master hadoop-2.5.1]$ ssh-copy-id slaver2
  
  [hadoop@master hadoop-2.5.1]$ bin/hadoop namenode -format
  [hadoop@master hadoop-2.5.1]$ sbin/start-dfs.sh 
  [hadoop@master hadoop-2.5.1]$ export PATH=/opt/jdk1.7.0_67/bin/:$PATH
  [hadoop@master hadoop-2.5.1]$ jps
  182 NameNode
  467 Jps
  [hadoop@master hadoop-2.5.1]$ sbin/start-yarn.sh 
  [hadoop@master hadoop-2.5.1]$ jps
  511 ResourceManager
  630 Jps
  182 NameNode 
  [hadoop@master hadoop-2.5.1]$ ssh slaver1 /opt/jdk1.7.0_67/bin/jps
  38 DataNode
  131 NodeManager
  240 Jps

  [hadoop@master spark-1.1.0-bin-2.5.1]$ sbin/start-all.sh 
  [hadoop@master spark-1.1.0-bin-2.5.1]$ /opt/jdk1.7.0_67/bin/jps  -m
  266 Jps -m
  132 Master --ip master --port 7077 --webui-port 8080
```

为ssh访问添加了sock5隧道，直接在windows本地通过浏览器访问web页面：

![Web View](https://cloud.githubusercontent.com/assets/667902/4495346/af4cbbf4-4a5a-11e4-9621-8a6c5d1a3a3a.png)
